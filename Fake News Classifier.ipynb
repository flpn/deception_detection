{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to concat all datasets together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_datasets(train, test, validation):\n",
    "    COLUMNS_LABELS = ['ID', 'Label', 'Statement', 'Subject', 'Speaker', \"Speaker's job\",\n",
    "                     'State info', 'Party affiliation', 'Barely true counts', 'False counts',\n",
    "                     'Half true counts', 'Mostly true counts', 'Pants on fire counts', 'Venue']\n",
    "    \n",
    "    train.columns = test.columns = validation.columns = COLUMNS_LABELS\n",
    "    \n",
    "    return pd.concat([train, test, validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker's job</th>\n",
       "      <th>State info</th>\n",
       "      <th>Party affiliation</th>\n",
       "      <th>Barely true counts</th>\n",
       "      <th>False counts</th>\n",
       "      <th>Half true counts</th>\n",
       "      <th>Mostly true counts</th>\n",
       "      <th>Pants on fire counts</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        Label                                          Statement  \\\n",
       "0  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "1    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "2   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "\n",
       "                              Subject         Speaker   Speaker's job  \\\n",
       "0  energy,history,job-accomplishments  scott-surovell  State delegate   \n",
       "1                      foreign-policy    barack-obama       President   \n",
       "2                         health-care    blog-posting             NaN   \n",
       "\n",
       "  State info Party affiliation  Barely true counts  False counts  \\\n",
       "0   Virginia          democrat                 0.0           0.0   \n",
       "1   Illinois          democrat                70.0          71.0   \n",
       "2        NaN              none                 7.0          19.0   \n",
       "\n",
       "   Half true counts  Mostly true counts  Pants on fire counts            Venue  \n",
       "0               1.0                 1.0                   0.0  a floor speech.  \n",
       "1             160.0               163.0                   9.0           Denver  \n",
       "2               3.0                 5.0                  44.0   a news release  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t')).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming labels into 'true' or 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_labels(label):\n",
    "    true_labels = ['half-true', 'mostly-true', 'true']\n",
    "    \n",
    "    return 'true' if label in true_labels else 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      half-true\n",
       "1    mostly-true\n",
       "2          false\n",
       "3      half-true\n",
       "4           true\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     true\n",
       "1     true\n",
       "2    false\n",
       "3     true\n",
       "4     true\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].apply(simplify_labels).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataframe into X and y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "    df['Label'] = df['Label'].apply(simplify_labels)\n",
    "    \n",
    "    X = df.iloc[:, 2].values\n",
    "    y = df.iloc[:, 1].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.',\n",
       "       'Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"',\n",
       "       'Health care reform legislation is likely to mandate free sex change surgeries.',\n",
       "       ...,\n",
       "       'John McCain and George Bush have \"absolutely no plan for universal health care.\"',\n",
       "       \"A new poll shows 62 percent support the president's plan to reform health care. That means ... letting you choose between keeping the private insurance you have and a public health insurance plan.\",\n",
       "       'No one claims the report vindicating New Jersey Gov. Chris Christie in the bridge scandal is conclusive.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'true', 'false', ..., 'true', 'false', 'false'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting X and y axis into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['We havent had a Republican senator in Washington for ... why, I think Clifford Case was our last Republican senator.',\n",
       "       \"Obama's Ten Point Plan to 'Change' The Second Amendment.Ban the manufacture, sale and possession of handguns.\",\n",
       "       'The House of Representatives has never sued a sitting president in all of U.S. history.',\n",
       "       ...,\n",
       "       \"If you have an investment for your child's education or own a mutual fund or a stock in a retirement plan, (Obama) is going to raise your taxes.\",\n",
       "       'Republicans are attempting to remove Barack Obama from Georgias Presidential Ballot in 2012.',\n",
       "       \"President Obama's own director of national intelligence, Admiral Blair, put it this way: 'High-value information came from interrogations in which those methods were used and provided a deeper understanding of the al-Qaida organization that was attacking this country.'\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'false', 'true', ..., 'false', 'true', 'true'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_documents(documents):\n",
    "    whitespace_tokenizer = WhitespaceTokenizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_documents = []\n",
    "    \n",
    "    for document in documents:\n",
    "        sentence = ' '.join([stemmer.stem(word.lower()) for word in whitespace_tokenizer.tokenize(document)])\n",
    "        stemmed_documents.append(sentence)\n",
    "    \n",
    "    return np.array(stemmed_documents, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when did the declin of coal start? it start when natur ga took off that start to begin in (presid georg w.) bush administration.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming_documents(X)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_data(labels):\n",
    "    return LabelEncoder().fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'true', 'false', ..., 'true', 'false', 'false'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_categorical_data(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y, dataset_type, tf_idf):    \n",
    "    X = stemming_documents(X)\n",
    "\n",
    "    if dataset_type == 'train':\n",
    "        X = tf_idf.fit_transform(X).toarray()\n",
    "    elif dataset_type == 'test' or dataset_type == 'validation':\n",
    "        X = tf_idf.transform(X).toarray()\n",
    "           \n",
    "    y = encode_categorical_data(y)\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "tf_idf = TfidfVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We havent had a Republican senator in Washington for ... why, I think Clifford Case was our last Republican senator.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_data(X_train, y_train, 'train', tf_idf)\n",
    "X_test, y_test = preprocess_data(X_test, y_test, 'test', tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ann_classifier(rate=0.1, lr=0.01):\n",
    "    classifier = Sequential()\n",
    "    \n",
    "    classifier.add(Dense(units=512, kernel_initializer='uniform', activation='relu', input_shape=(10229,)))\n",
    "    classifier.add(Dropout(rate=rate))\n",
    "    classifier.add(Dense(units=512, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(rate=rate))\n",
    "    classifier.add(Dense(units=256, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(rate=rate))\n",
    "    classifier.add(Dense(units=128, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(rate=rate))\n",
    "    classifier.add(Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=32, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "#    adam = optimizers.Adam(lr=lr)\n",
    "#    classifier.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    rmsprop = optimizers.RMSprop(lr=lr)\n",
    "    classifier.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "tf_idf = TfidfVectorizer(max_df=0.5)\n",
    "\n",
    "X_train, y_train = preprocess_data(X_train, y_train, 'train', tf_idf)\n",
    "X_test, y_test = preprocess_data(X_test, y_test, 'test', tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7193 samples, validate on 2398 samples\n",
      "Epoch 1/3\n",
      "7193/7193 [==============================] - 17s 2ms/step - loss: 0.7007 - acc: 0.5614 - val_loss: 0.6861 - val_acc: 0.6122\n",
      "Epoch 2/3\n",
      "7193/7193 [==============================] - 16s 2ms/step - loss: 0.6195 - acc: 0.6840 - val_loss: 0.8390 - val_acc: 0.6163\n",
      "Epoch 3/3\n",
      "7193/7193 [==============================] - 16s 2ms/step - loss: 0.4637 - acc: 0.8148 - val_loss: 0.7222 - val_acc: 0.6193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee05f0beb8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = build_ann_classifier()\n",
    "classifier.fit(X_train, y_train, batch_size=50, epochs=3, shuffle=True, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a single news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(news):\n",
    "    news = np.array(news)\n",
    "    news = tf_idf.transform(news).toarray()\n",
    "    \n",
    "    return classifier.predict(news) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7193 samples, validate on 2398 samples\n",
      "Epoch 1/3\n",
      "7193/7193 [==============================] - 23s 3ms/step - loss: 7.2459 - acc: 0.5330 - val_loss: 8.8589 - val_acc: 0.4504\n",
      "Epoch 2/3\n",
      "7193/7193 [==============================] - 15s 2ms/step - loss: 7.2679 - acc: 0.4606 - val_loss: 0.6797 - val_acc: 0.5496\n",
      "Epoch 3/3\n",
      "7193/7193 [==============================] - 16s 2ms/step - loss: 0.6909 - acc: 0.5943 - val_loss: 0.9429 - val_acc: 0.5901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feeb5c0a908>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "tf_idf = TfidfVectorizer(max_df=0.5)\n",
    "\n",
    "news_test = X_test[0]\n",
    "news_test_label = y_test[0]\n",
    "\n",
    "X_train, y_train = preprocess_data(X_train, y_train, 'train', tf_idf)\n",
    "X_test, y_test = preprocess_data(X_test, y_test, 'test', tf_idf)\n",
    "\n",
    "classifier = build_ann_classifier()\n",
    "classifier.fit(X_train, y_train, batch_size=50, epochs=3, shuffle=False, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Obama wrote a thesis at Columbia University in which he criticized \"plutocratic thugs\" and said the Constitution gave Americans \"the shackles of hypocrisy.\"'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56807]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_news([news_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, build_fn, k, batch, epochs):\n",
    "    classifier = KerasClassifier(build_fn=build_fn, batch_size=batch, epochs=epochs)\n",
    "    accuracies = cross_val_score(estimator=classifier, X=X, y=y, cv=k)\n",
    "    mean = accuracies.mean()\n",
    "    variance = accuracies.std()\n",
    "    \n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_datasets(pd.read_csv('datasets/train.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/test.tsv', sep='\\t'),\n",
    "                pd.read_csv('datasets/valid.tsv', sep='\\t'))\n",
    "X, y = split_dataframe(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "tf_idf = TfidfVectorizer(max_df=0.5)\n",
    "\n",
    "X_train, y_train = preprocess_data(X_train, y_train, 'train', tf_idf)\n",
    "X_test, y_test = preprocess_data(X_test, y_test, 'test', tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7672/7672 [==============================] - 25s 3ms/step - loss: 0.6822 - acc: 0.5829\n",
      "Epoch 2/3\n",
      "7672/7672 [==============================] - 15s 2ms/step - loss: 0.5779 - acc: 0.7255\n",
      "Epoch 3/3\n",
      "7672/7672 [==============================] - 17s 2ms/step - loss: 0.3845 - acc: 0.8526\n",
      "1919/1919 [==============================] - 1s 618us/step\n",
      "Epoch 1/3\n",
      "7673/7673 [==============================] - 18s 2ms/step - loss: 0.7458 - acc: 0.5785\n",
      "Epoch 2/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.5821 - acc: 0.7327\n",
      "Epoch 3/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.4032 - acc: 0.8504\n",
      "1918/1918 [==============================] - 1s 487us/step\n",
      "Epoch 1/3\n",
      "7673/7673 [==============================] - 19s 2ms/step - loss: 0.7790 - acc: 0.5637\n",
      "Epoch 2/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.6560 - acc: 0.6655\n",
      "Epoch 3/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.5594 - acc: 0.7504\n",
      "1918/1918 [==============================] - 1s 516us/step\n",
      "Epoch 1/3\n",
      "7673/7673 [==============================] - 19s 2ms/step - loss: 0.7144 - acc: 0.5719\n",
      "Epoch 2/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.6036 - acc: 0.7121\n",
      "Epoch 3/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.4284 - acc: 0.8282\n",
      "1918/1918 [==============================] - 1s 522us/step\n",
      "Epoch 1/3\n",
      "7673/7673 [==============================] - 19s 3ms/step - loss: 0.7104 - acc: 0.5613\n",
      "Epoch 2/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.7683 - acc: 0.6609\n",
      "Epoch 3/3\n",
      "7673/7673 [==============================] - 17s 2ms/step - loss: 0.5072 - acc: 0.7865\n",
      "1918/1918 [==============================] - 1s 516us/step\n"
     ]
    }
   ],
   "source": [
    "accuracy, variance = k_fold_cross_validation(X_train, y_train, build_ann_classifier, 5, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6030652305147586"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008634168876144394"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
